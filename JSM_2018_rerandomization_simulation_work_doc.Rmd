---
title: "JSM 2018 Rerandomization Simulations"
author: "Crystal Shaw"
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_notebook:
    toc: yes
    toc_depth: '2'
    theme: "yeti"
bibliography: JSM2018bib.bib
csl: ieee-with-url.csl
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pacman, echo = FALSE, message = FALSE, warning = FALSE}
if (!require("pacman")) 
install.packages("pacman", repos = 'http://cran.us.r-project.org')
options(scipen = 999)
```

The following packages were used in the proceeding analyses:

```{r packages, message = FALSE, warning = FALSE, echo = TRUE}
p_load("tidyverse", "MASS", "GreedyExperimentalDesign", "knitr", "kableExtra")
```

# Introduction/Motivation

Randomization has long been accepted as the "gold standard" in experimental design due to its ability to guard against confounding by creating balanced covariates across treatment groups on average.  Once underway, a randomized control trial (RCT) possesses a specified randomization scheme which when left to chance can produce unacceptable balance in one or more covariates more often than expected.  For a fixed $\alpha$ level, the probability of a significant difference in at least one covariate is given by $$1 - (1 - \alpha)^k, $$ where $k$ is the number of independent covariates. Figure \ref{fig:Covariate Imbalance Plot} illustrates the near certainty of covariate imbalances in high dimensional data settings.

```{r Covariate Imbalance Plot, fig.align = "center", fig.cap = "Probability of imbalance in at least one covariate.", out.width = "55%"}
cov_imb <- function(n){
  1 - (1 - 0.05)^n
}

ggplot(data = data.frame(x = 0), mapping = aes(x = x)) +
  stat_function(fun = cov_imb) + xlim(0,100) + 
  labs(y = "P(at least one covariate imbalance)", 
       x = "Number of covariates", 
       title = "Probability of covariate imbalance as a function of 
       the number of covariates") + 
  theme_minimal()
```

Rerandomization, dubbed the “platinum standard” in experimental design [@Tukey1993][@Treasure1998], can ensure covariate balance and preserve the integrity of inferences. In practice, the balance between design optimality and feasibility is crucial.  The computationally intensive nature of this allocation procedure and subsequent analysis necessitates a deeper understanding of the interplay between the reduction in variance of both covariate mean differences and treatment effects, the correlation among the measured covariates, and the effect of these reduced measures on coverage probabilities for the mean difference in treatment effect. Through a series of simulation studies, we explore the sensitivity of traditional testing procedures to rerandomization based on various criteria including the affinely invariant Mahalanobis distance [@Morgan2012] and tiered covariate balancing [@LockMORGAN]. 


# Simulation Studies: Rerandomize all covariates  

In the following simulated scenarios, we generate the data for 100 observations and 25 covariates.  

Note to self:  Want to include different kinds of covariates... start with all continuous predictors, then start adding in categorical 

Note to self:  Need to model correlation with outcome to see how that effects inference (see Kreiger, et al pg 2)

Strategy:  We want to consider an additive treatment effect:  
$${\bf y}(1) =  {\bf y}(0) + \tau$$ and test the hypotheses:
\begin{align*}
H_0&:  \tau = 0\\
H_a&:  \tau \neq 0
\end{align*}

Under this null hypothesis, the outcome is unaffected by group assignment so new randomizations can be simulated directly leaving the outcomes untouched.  For testing that $H_0$ is equal to some other value, refer to page 16 of Lock's dissertation.  

We want to assess the sensitivity of t-tests to rerandomized data by calculating the type I error rate under various parameter settings.  

Recall that Type I error is the rejection of a true null hypothesis.  

Our null hypothesis is that there is no treatment effect.  Thus we can generate the effect data irrespective of treatment assignment of the observations.

We want to 

## Scenario 1A:  Continuous covariates; covariance correlation = 0; outcome correlation = 0 

```{r Sim1A Parameters, echo = TRUE}
samp_size <- 100    #Specify the number of observations
num_cov <- 25       #Specify the number of covariates
C <- diag(num_cov + 1)  #Specify matrix of correlations
```

```{r Sim1A, echo = TRUE}
set.seed(5172018)

#Generate covariates, treatment effects, and merging the data 
obs <- mvrnorm(n = samp_size, mu = rep(0, num_cov + 1), Sigma = C)
E <- rnorm(n = samp_size, mean = 0, sd = 1) 
data <- cbind(obs, E)
```

# Simulation Studies: Rerandomize tiers of covariates  

# Simulation Studies: Rerandomize with blocking  

Note to self:  Typical variables that should be blocked on:  age, sex



# Conclusion

\pagebreak

# References